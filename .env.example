# =============================================================================
# Autonomous Tech Research Agent - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values
# =============================================================================

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Provider selection: "gemini", "groq", or "auto" (uses Gemini with Groq fallback)
LLM_PROVIDER=auto

# -----------------------------------------------------------------------------
# Google Gemini (Recommended - Generous FREE tier)
# Get your FREE API key at: https://aistudio.google.com/apikey
# 
# MODEL LIMITS (Free Tier):
#   gemini-2.0-flash: 1500 requests/day (RECOMMENDED)
#   gemini-2.5-flash: 20 requests/day (LIMITED!)
# -----------------------------------------------------------------------------
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_MODEL=gemini-2.0-flash

# -----------------------------------------------------------------------------
# Groq (Alternative - Limited FREE tier: 100k tokens/day)
# Get your FREE API key at: https://console.groq.com/keys
# -----------------------------------------------------------------------------
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# Legacy model setting (deprecated, use GEMINI_MODEL/GROQ_MODEL instead)
LLM_MODEL=llama-3.3-70b-versatile

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false

# Agent Configuration
AGENT_MAX_ITERATIONS=15
AGENT_MAX_EXECUTION_TIME=180
AGENT_MEMORY_SIZE=100
DEFAULT_MAX_SOURCES=8

# Memory Database (SQLite for persistent storage)
MEMORY_DB_PATH=./data/memory.db

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
